services:
  # HDFS Namenode
  namenode:
    # image: apache/hadoop:3.3.6
    image: custom-hadoop-namenode:3.3.6-java11
    container_name: namenode
    hostname: namenode
    environment:
      - ENSURE_NAMENODE_DIR=/tmp/hadoop-root/dfs/name
      - CLUSTER_NAME=hadoopvideo
      # - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      # - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
    env_file:
      - ./hadoop.env
    command: ["hdfs", "namenode"]
    volumes:
      - namenode-data:/hadoop/dfs/name
    ports:
      - "50070:50070"  # NameNode web UI
      - "8020:8020"    # HDFS port
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # HDFS Datanode
  datanode:
    # image: apache/hadoop:3.3.6
    image: custom-hadoop-datanode:3.3.6-java11    
    container_name: datanode
    hostname: datanode
    environment:
      - HDFS_CONF_dfs_datanode_data_dir=/hadoop/dfs/data
      # - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    env_file:
      - ./hadoop.env
    command: ["hdfs", "datanode"]
    volumes:
      - datanode-data:/hadoop/dfs/data
    depends_on:
      - namenode
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Kafka Brokers
  kafka-1:
    image: bitnami/kafka:3.8.0
    container_name: kafka-1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_KRAFT_CLUSTER_ID=d8ce1515-401e-44d4-a444-1b6dba479047
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_HEAP_OPTS=-Xmx2G -Xms2G
    volumes:
      - ./server-1.properties:/opt/bitnami/kafka/config/server.properties
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"
  kafka-2:
    image: bitnami/kafka:3.8.0
    container_name: kafka-2
    ports:
      - "9095:9095"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_KRAFT_CLUSTER_ID=d8ce1515-401e-44d4-a444-1b6dba479047
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_HEAP_OPTS=-Xmx2G -Xms2G
    volumes:
      - ./server-2.properties:/opt/bitnami/kafka/config/server.properties
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Kafka Service
  kafka-service:
    image: alexflames77/kafka_service:latest
    container_name: kafka-service
    environment:
      - BOOTSTRAP_SERVERS=kafka-1:9092,kafka-2:9095
    networks:
      - kafka-net
    ports:
      - "9091:9091"
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"
    depends_on:
      - kafka-1
      - kafka-2

  # Flink JobManager
  jobmanager:
    image: flink:1.17.1
    container_name: jobmanager
    hostname: jobmanager
    ports:
      - "8081:8081"
      - "6123:6123"
      - "6124:6124"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.registration.timeout: 5 min
    networks:
      - kafka-net
    restart: always

  # Flink TaskManager
  taskmanager:
    image: flink:1.17.1
    container_name: taskmanager
    hostname: taskmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.registration.timeout: 5 min
    networks:
      - kafka-net
    restart: always
    depends_on:
      - jobmanager

  # Flink Job
  flink-job:
    image: alexflames77/flink_job:latest
    container_name: flink-job
    environment:
      - FLINK_JOBMANAGER_HOST=jobmanager
      - FLINK_JOBMANAGER_PORT=8081
    command: >
      /bin/bash -c "
      java 
      --add-opens=java.base/java.util=ALL-UNNAMED 
      --add-opens=java.base/java.lang=ALL-UNNAMED 
      --add-opens=java.base/java.lang.invoke=ALL-UNNAMED 
      --add-opens=java.base/java.nio=ALL-UNNAMED 
      --add-opens=java.base/sun.nio.ch=ALL-UNNAMED 
      "
    networks:
      - kafka-net
    depends_on:
      - jobmanager
      - taskmanager
    restart: on-failure
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # spark-job:
  #   image: alexflames77/spark_job:latest
  #   environment:
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_APPLICATION_JAR_LOCATION=/opt/spark-apps/spark-ml-job.jar
  #     - SPARK_APPLICATION_MAIN_CLASS=SparkMLJob
  #   networks:
  #     - kafka-net
  #   restart: always
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: "1"
  #         memory: "2g"
  #   depends_on:
  #     - kafka-1
  #     - kafka-2

  # Spark Master
  spark-master:
    image: bitnami/spark:3.5.4
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Spark Worker
  spark-worker:
    image: bitnami/spark:3.5.4
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark-master
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Spark Job
  spark-job:
    image: alexflames77/spark_job:latest
    container_name: spark-job
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./models/saved_model:/opt/spark-apps/models/saved_model
    depends_on:
      - spark-master
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Prometheus
  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      -  prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

  # Grafana
  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-storage:/var/lib/grafana
    networks:
      - kafka-net
    restart: always
    # deploy:
    #   resources:
    #     limits:
    #       cpus: "1"
    #       memory: "2g"

networks:
  kafka-net:
    driver: bridge

volumes:
  namenode-data:
  datanode-data:
  grafana-storage:
  prometheus-data:
