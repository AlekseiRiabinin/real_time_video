{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbcc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7c06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up visualization style\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d80f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 0. MAIN ANALYSIS\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_producer_metrics(producer_dir):\n",
    "    \"\"\"Load all metrics for a single producer from separate CSV files with specific naming\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # Mapping of our metric names to your filenames\n",
    "    file_mapping = {\n",
    "        'CPU': 'CPU.csv',\n",
    "        'Memory': 'Memory.csv',\n",
    "        'Disk read': 'Disk_read.csv',\n",
    "        'Disk write': 'Disk_write.csv',\n",
    "        'Network received': 'Network_received.csv',\n",
    "        'Network sent': 'Network_sent.csv',\n",
    "        'Messages consumption time': 'Msg_cons_time.csv',\n",
    "        'Consumption lag': 'Cons_lag.csv',\n",
    "        'Average latency': 'Avg_latency.csv',\n",
    "        'Throughput': 'Throughput.csv',\n",
    "        'Frames produced': 'Frame_prod.csv',\n",
    "        'Messages consumed': 'Msg_cons.csv'\n",
    "    }\n",
    "    \n",
    "    for metric_name, file_name in file_mapping.items():\n",
    "        file_path = Path(producer_dir) / file_name\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, header=None, names=['timestamp', 'value'])\n",
    "                metrics[metric_name] = df\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read {file_path}: {str(e)}\")\n",
    "                metrics[metric_name] = pd.DataFrame(columns=['timestamp', 'value'])\n",
    "        else:\n",
    "            print(f\"Warning: File not found - {file_path}\")\n",
    "            metrics[metric_name] = pd.DataFrame(columns=['timestamp', 'value'])\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e44a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_producer_stats(metrics):\n",
    "    \"\"\"Calculate statistics from a producer's metrics\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    # Performance Overview\n",
    "    if not metrics['Frames produced'].empty:\n",
    "        stats['frame_production_rate'] = metrics['Frames produced']['value'].diff().mean()  # FPS as rate of change\n",
    "        stats['frames_produced_total'] = metrics['Frames produced']['value'].iloc[-1]  # Assuming cumulative\n",
    "    else:\n",
    "        stats['frame_production_rate'] = 0\n",
    "        stats['frames_produced_total'] = 0\n",
    "    \n",
    "    if not metrics['Average latency'].empty:\n",
    "        stats['avg_latency'] = metrics['Average latency']['value'].mean() * 1000  # Convert to ms\n",
    "    else:\n",
    "        stats['avg_latency'] = 0\n",
    "    \n",
    "    if not metrics['Consumption lag'].empty:\n",
    "        stats['consumer_lag'] = metrics['Consumption lag']['value'].mean()\n",
    "    else:\n",
    "        stats['consumer_lag'] = 0\n",
    "    \n",
    "    if not metrics['Messages consumption time'].empty:\n",
    "        stats['message_consumption_time'] = metrics['Messages consumption time']['value'].mean() * 1000  # Convert to ms\n",
    "    else:\n",
    "        stats['message_consumption_time'] = 0\n",
    "    \n",
    "    if not metrics['Messages consumed'].empty:\n",
    "        stats['messages_consumed_total'] = metrics['Messages consumed']['value'].iloc[-1]  # Assuming cumulative\n",
    "    else:\n",
    "        stats['messages_consumed_total'] = 0\n",
    "    \n",
    "    # Resource Utilization\n",
    "    if not metrics['CPU'].empty:\n",
    "        stats['cpu_usage'] = metrics['CPU']['value'].mean()\n",
    "    else:\n",
    "        stats['cpu_usage'] = 0\n",
    "    \n",
    "    if not metrics['Memory'].empty:\n",
    "        stats['memory_usage'] = metrics['Memory']['value'].mean()\n",
    "    else:\n",
    "        stats['memory_usage'] = 0\n",
    "    \n",
    "    if not metrics['Disk read'].empty and not metrics['Disk write'].empty:\n",
    "        stats['disk_read_write'] = (metrics['Disk read']['value'].mean() + metrics['Disk write']['value'].mean()) / 2\n",
    "    else:\n",
    "        stats['disk_read_write'] = 0\n",
    "    \n",
    "    if not metrics['Network received'].empty and not metrics['Network sent'].empty:\n",
    "        stats['network_io'] = (metrics['Network received']['value'].mean() + metrics['Network sent']['value'].mean()) / 2\n",
    "    else:\n",
    "        stats['network_io'] = 0\n",
    "    \n",
    "    # Throughput Analysis\n",
    "    if not metrics['Throughput'].empty:\n",
    "        stats['avg_throughput'] = metrics['Throughput']['value'].mean()\n",
    "        stats['peak_throughput'] = metrics['Throughput']['value'].max()\n",
    "    else:\n",
    "        stats['avg_throughput'] = 0\n",
    "        stats['peak_throughput'] = 0\n",
    "    \n",
    "    # Latency Analysis\n",
    "    if not metrics['Average latency'].empty:\n",
    "        stats['p99_latency'] = metrics['Average latency']['value'].quantile(0.99) * 1000  # Convert to ms\n",
    "    else:\n",
    "        stats['p99_latency'] = 0\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55a76af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_producers(base_dir):\n",
    "    \"\"\"Analyze all producers in the base directory\"\"\"\n",
    "    producer_dirs = glob.glob(f\"{base_dir}/*/\")  # Get all subdirectories\n",
    "    \n",
    "    all_stats = {}\n",
    "    \n",
    "    for producer_dir in producer_dirs:\n",
    "        producer_name = Path(producer_dir).name\n",
    "        try:\n",
    "            print(f\"Processing {producer_name}...\")\n",
    "            metrics = load_producer_metrics(producer_dir)\n",
    "            stats = calculate_producer_stats(metrics)\n",
    "            all_stats[producer_name] = stats\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {producer_name}: {str(e)}\")\n",
    "    \n",
    "    return all_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c9bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance_overview(stats_dict):\n",
    "    \"\"\"Print Performance Overview table\"\"\"\n",
    "    print(\"\\nTable X - Real-Time Video Processing Metrics by Producer\")\n",
    "    print(\"{:<15} {:<25} {:<20} {:<15} {:<15} {:<25} {:<20}\".format(\n",
    "        \"Producer\", \"Frame Production Rate (fps)\", \"Frames Produced (total)\", \n",
    "        \"Avg Latency (ms)\", \"Consumer Lag (ms)\", \"Message Consumpt. Time (ms)\", \n",
    "        \"Messages Consumed (total)\"))\n",
    "    \n",
    "    for producer, stats in stats_dict.items():\n",
    "        print(\"{:<15} {:<25.2f} {:<20.2f} {:<15.2f} {:<15.2f} {:<25.2f} {:<20.2f}\".format(\n",
    "            producer, stats['frame_production_rate'], stats['frames_produced_total'],\n",
    "            stats['avg_latency'], stats['consumer_lag'], \n",
    "            stats['message_consumption_time'], stats['messages_consumed_total']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391627ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resource_utilization(stats_dict):\n",
    "    \"\"\"Print Resource Utilization table\"\"\"\n",
    "    print(\"\\nTable X - Resource Utilization by Producer\")\n",
    "    print(\"{:<15} {:<15} {:<15} {:<20} {:<15}\".format(\n",
    "        \"Producer\", \"CPU Usage (%)\", \"Memory Usage (MB)\", \n",
    "        \"Disk Read/Write (MB/s)\", \"Network I/O (MB/s)\"))\n",
    "    \n",
    "    for producer, stats in stats_dict.items():\n",
    "        print(\"{:<15} {:<15.2f} {:<15.2f} {:<20.2f} {:<15.2f}\".format(\n",
    "            producer, stats['cpu_usage'], stats['memory_usage'],\n",
    "            stats['disk_read_write'], stats['network_io']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e572ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_throughput_analysis(stats_dict):\n",
    "    \"\"\"Print Throughput Analysis table\"\"\"\n",
    "    print(\"\\nTable X - Throughput by Producer\")\n",
    "    print(\"{:<15} {:<20} {:<20} {:<15} {:<15}\".format(\n",
    "        \"Producer\", \"Avg. Throughput (fps)\", \"Peak Throughput (fps)\", \n",
    "        \"CPU Usage (%)\", \"Memory usage (MB)\"))\n",
    "    \n",
    "    for producer, stats in stats_dict.items():\n",
    "        print(\"{:<15} {:<20.2f} {:<20.2f} {:<15.2f} {:<15.2f}\".format(\n",
    "            producer, stats['avg_throughput'], stats['peak_throughput'],\n",
    "            stats['cpu_usage'], stats['memory_usage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc4794fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_latency_analysis(stats_dict):\n",
    "    \"\"\"Print Latency Analysis table\"\"\"\n",
    "    print(\"\\nTable X - Latency by Producer\")\n",
    "    print(\"{:<15} {:<20} {:<20} {:<15} {:<15}\".format(\n",
    "        \"Producer\", \"Avg. Latency (ms)\", \"P99 Latency (ms)\", \n",
    "        \"CPU Usage (%)\", \"Memory usage (MB)\"))\n",
    "    \n",
    "    for producer, stats in stats_dict.items():\n",
    "        print(\"{:<15} {:<20.2f} {:<20.2f} {:<15.2f} {:<15.2f}\".format(\n",
    "            producer, stats['avg_latency'], stats['p99_latency'],\n",
    "            stats['cpu_usage'], stats['memory_usage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd8bdf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_to_file(results, output_file=\"results.txt\"):\n",
    "    \"\"\"Write all analysis results to a file with timestamp\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Write header with timestamp\n",
    "        f.write(f\"Performance Analysis Results - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        # Performance Overview\n",
    "        f.write(\"Table X - Real-Time Video Processing Metrics by Producer\\n\")\n",
    "        f.write(\"{:<15} {:<25} {:<20} {:<15} {:<15} {:<25} {:<20}\\n\".format(\n",
    "            \"Producer\", \"Frame Production Rate (fps)\", \"Frames Produced (total)\", \n",
    "            \"Avg Latency (ms)\", \"Consumer Lag (ms)\", \"Message Consumpt. Time (ms)\", \n",
    "            \"Messages Consumed (total)\"))\n",
    "        \n",
    "        for producer, stats in results.items():\n",
    "            f.write(\"{:<15} {:<25.2f} {:<20.2f} {:<15.2f} {:<15.2f} {:<25.2f} {:<20.2f}\\n\".format(\n",
    "                producer, stats['frame_production_rate'], stats['frames_produced_total'],\n",
    "                stats['avg_latency'], stats['consumer_lag'], \n",
    "                stats['message_consumption_time'], stats['messages_consumed_total']))\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Resource Utilization\n",
    "        f.write(\"Table X - Resource Utilization by Producer\\n\")\n",
    "        f.write(\"{:<15} {:<15} {:<15} {:<20} {:<15}\\n\".format(\n",
    "            \"Producer\", \"CPU Usage (%)\", \"Memory Usage (MB)\", \n",
    "            \"Disk Read/Write (MB/s)\", \"Network I/O (MB/s)\"))\n",
    "        \n",
    "        for producer, stats in results.items():\n",
    "            f.write(\"{:<15} {:<15.2f} {:<15.2f} {:<20.2f} {:<15.2f}\\n\".format(\n",
    "                producer, stats['cpu_usage'], stats['memory_usage'],\n",
    "                stats['disk_read_write'], stats['network_io']))\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Throughput Analysis\n",
    "        f.write(\"Table X - Throughput by Producer\\n\")\n",
    "        f.write(\"{:<15} {:<20} {:<20} {:<15} {:<15}\\n\".format(\n",
    "            \"Producer\", \"Avg. Throughput (fps)\", \"Peak Throughput (fps)\", \n",
    "            \"CPU Usage (%)\", \"Memory usage (MB)\"))\n",
    "        \n",
    "        for producer, stats in results.items():\n",
    "            f.write(\"{:<15} {:<20.2f} {:<20.2f} {:<15.2f} {:<15.2f}\\n\".format(\n",
    "                producer, stats['avg_throughput'], stats['peak_throughput'],\n",
    "                stats['cpu_usage'], stats['memory_usage']))\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # Latency Analysis\n",
    "        f.write(\"Table X - Latency by Producer\\n\")\n",
    "        f.write(\"{:<15} {:<20} {:<20} {:<15} {:<15}\\n\".format(\n",
    "            \"Producer\", \"Avg. Latency (ms)\", \"P99 Latency (ms)\", \n",
    "            \"CPU Usage (%)\", \"Memory usage (MB)\"))\n",
    "        \n",
    "        for producer, stats in results.items():\n",
    "            f.write(\"{:<15} {:<20.2f} {:<20.2f} {:<15.2f} {:<15.2f}\\n\".format(\n",
    "                producer, stats['avg_latency'], stats['p99_latency'],\n",
    "                stats['cpu_usage'], stats['memory_usage']))\n",
    "        \n",
    "        print(f\"\\nResults successfully written to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82332e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fs2...\n",
      "Processing akka...\n",
      "Processing kafka...\n",
      "Processing zio...\n",
      "Processing cats...\n",
      "\n",
      "Results successfully written to performance_results.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_directory = \"data\"  # Your base directory containing producer folders\n",
    "    output_filename = \"performance_results.txt\"\n",
    "    \n",
    "    # Analyze all producers\n",
    "    all_stats = analyze_all_producers(base_directory)\n",
    "    \n",
    "    # Write results to file\n",
    "    write_results_to_file(all_stats, output_filename)\n",
    "    \n",
    "    # Also print to console (optional)\n",
    "    # Uncomment these if needed to see results in console too\n",
    "    # print_performance_overview(all_stats)\n",
    "    # print_resource_utilization(all_stats)\n",
    "    # print_throughput_analysis(all_stats)\n",
    "    # print_latency_analysis(all_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "329238b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 1. DATA LOADING & PREPROCESSING\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d858c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metric(file_path, metric_name):\n",
    "    \"\"\"Load single metric CSV with robust timestamp handling\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, names=['timestamp', metric_name])\n",
    "        \n",
    "        # Convert timestamp with multiple format attempts\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%H:%M:%S')\n",
    "        except:\n",
    "            try:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], format='%H:%M:%S.%f')\n",
    "            except:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Handle duplicates by averaging\n",
    "        return df.groupby('timestamp').mean().reset_index()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0b4b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_producer_data(producer_dir):\n",
    "    \"\"\"Load all metrics for a producer\"\"\"\n",
    "    file_mapping = {\n",
    "        'CPU': 'CPU.csv',\n",
    "        'Memory': 'Memory.csv',\n",
    "        'Disk_read': 'Disk_read.csv',\n",
    "        'Disk_write': 'Disk_write.csv',\n",
    "        'Network_received': 'Network_received.csv',\n",
    "        'Network_sent': 'Network_sent.csv',\n",
    "        'Msg_cons_time': 'Msg_cons_time.csv',\n",
    "        'Cons_lag': 'Cons_lag.csv',\n",
    "        'Avg_latency': 'Avg_latency.csv',\n",
    "        'Throughput': 'Throughput.csv',\n",
    "        'Frame_prod': 'Frame_prod.csv',\n",
    "        'Msg_cons': 'Msg_cons.csv'\n",
    "    }\n",
    "    \n",
    "    dfs = []\n",
    "    for metric_name, file_name in file_mapping.items():\n",
    "        file_path = Path(producer_dir) / file_name\n",
    "        if file_path.exists():\n",
    "            df = load_metric(file_path, metric_name)\n",
    "            if not df.empty:\n",
    "                dfs.append(df.set_index('timestamp'))\n",
    "    \n",
    "    if dfs:\n",
    "        # Merge all metrics with forward filling\n",
    "        combined = pd.concat(dfs, axis=1).sort_index()\n",
    "        return combined.ffill().interpolate().fillna(0)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d087a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_producers(base_dir=\"data\"):\n",
    "    \"\"\"Load all producers' data\"\"\"\n",
    "    return {\n",
    "        Path(producer_dir).name: load_producer_data(producer_dir)\n",
    "        for producer_dir in glob.glob(f\"{base_dir}/*/\")\n",
    "        if not load_producer_data(producer_dir).empty\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cfe74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 2. CORE ANALYSIS FUNCTIONS\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47285c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(data, title):\n",
    "    \"\"\"Plot correlation heatmap\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(data.corr(), annot=True, cmap='coolwarm', \n",
    "                center=0, fmt=\".2f\", linewidths=.5)\n",
    "    plt.title(f'Correlation Matrix - {title}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ca1d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_decomposition(data, metric, period=30):\n",
    "    \"\"\"Decompose time series into components\"\"\"\n",
    "    decomposition = seasonal_decompose(data[metric].dropna(), \n",
    "                                     period=period, model='additive')\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(12, 8))\n",
    "    decomposition.observed.plot(ax=axes[0], title='Observed')\n",
    "    decomposition.trend.plot(ax=axes[1], title='Trend')\n",
    "    decomposition.seasonal.plot(ax=axes[2], title='Seasonal')\n",
    "    decomposition.resid.plot(ax=axes[3], title='Residual')\n",
    "    plt.suptitle(f'Time Series Decomposition - {metric}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46b034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. CRITICAL PERFORMANCE ANALYSES\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06a81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck_analysis(data, producer_name):\n",
    "    \"\"\"Identify system bottlenecks\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Create named Series for the calculated metrics\n",
    "    network_total = (data['Network_received'] + data['Network_sent']).rename('Network Total I/O')\n",
    "    disk_total = (data['Disk_read'] + data['Disk_write']).rename('Disk Total I/O')\n",
    "    \n",
    "    # CPU vs Throughput\n",
    "    sns.scatterplot(data=data, x='CPU', y='Throughput', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('CPU vs Throughput')\n",
    "    \n",
    "    # Memory vs Latency\n",
    "    sns.scatterplot(data=data, x='Memory', y='Avg_latency', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Memory vs Latency')\n",
    "    \n",
    "    # Network vs Frames\n",
    "    sns.scatterplot(x=network_total, y=data['Frame_prod'], ax=axes[1, 0])\n",
    "    axes[1, 0].set(xlabel='Network Total I/O', ylabel='Frame Production',\n",
    "                  title='Network I/O vs Frame Production')\n",
    "    \n",
    "    # Disk vs Consumption Time\n",
    "    sns.scatterplot(x=disk_total, y=data['Msg_cons_time'], ax=axes[1, 1])\n",
    "    axes[1, 1].set(xlabel='Disk Total I/O', ylabel='Message Consumption Time',\n",
    "                  title='Disk I/O vs Consumption Time')\n",
    "    \n",
    "    plt.suptitle(f'Bottleneck Analysis - {producer_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    bottlenecks = []\n",
    "    if (data['CPU'] > 90).any():\n",
    "        bottlenecks.append(\"High CPU (>90%)\")\n",
    "    if (data['Memory'] > data['Memory'].quantile(0.9)).any():\n",
    "        bottlenecks.append(\"High Memory (top 10%)\")\n",
    "    \n",
    "    return bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1addb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resource_efficiency(data, producer_name):\n",
    "    \"\"\"Analyze resource utilization efficiency\"\"\"\n",
    "    data['frames_per_cpu'] = data['Frame_prod'] / (data['CPU'] + 0.01)\n",
    "    data['frames_per_mem'] = data['Frame_prod'] / (data['Memory'] + 0.01)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    data['frames_per_cpu'].plot(ax=axes[0], title='Frames per CPU %')\n",
    "    data['frames_per_mem'].plot(ax=axes[1], title='Frames per Memory MB')\n",
    "    plt.suptitle(f'Resource Efficiency - {producer_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'avg_cpu_efficiency': data['frames_per_cpu'].mean(),\n",
    "        'avg_mem_efficiency': data['frames_per_mem'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdfce821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 4. EXECUTION & REPORTING\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cefe1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_producer(name, data):\n",
    "    \"\"\"Run full analysis for one producer\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ANALYZING: {name.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 1. Correlation Analysis\n",
    "    print(\"\\n[INFRASTRUCTURE VS PERFORMANCE CORRELATIONS]\")\n",
    "    plot_correlations(data[['CPU', 'Memory', 'Disk_read', 'Disk_write',\n",
    "                          'Network_received', 'Network_sent', \n",
    "                          'Throughput', 'Avg_latency']], name)\n",
    "    \n",
    "    # 2. Time Series Analysis\n",
    "    print(\"\\n[TIME SERIES DECOMPOSITION]\")\n",
    "    time_series_decomposition(data, 'Throughput')\n",
    "    \n",
    "    # 3. Critical Analyses\n",
    "    print(\"\\n[BOTTLENECK ANALYSIS]\")\n",
    "    bottlenecks = bottleneck_analysis(data, name)\n",
    "    print(\"Detected Bottlenecks:\", bottlenecks if bottlenecks else \"None\")\n",
    "    \n",
    "    print(\"\\n[RESOURCE EFFICIENCY]\")\n",
    "    efficiency = resource_efficiency(data, name)\n",
    "    print(f\"CPU Efficiency: {efficiency['avg_cpu_efficiency']:.2f} frames/%\")\n",
    "    print(f\"Memory Efficiency: {efficiency['avg_mem_efficiency']:.2f} frames/MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07507e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(producers_data):\n",
    "    \"\"\"Generate complete analysis report\"\"\"\n",
    "    print(\"=== KAFKA PRODUCERS PERFORMANCE ANALYSIS REPORT ===\")\n",
    "    print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    for name, data in producers_data.items():\n",
    "        analyze_producer(name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fec22c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 5. MAIN EXECUTION\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load all data\n",
    "    producers_data = load_all_producers()\n",
    "    \n",
    "    # Generate complete report\n",
    "    if producers_data:\n",
    "        generate_report(producers_data)\n",
    "    else:\n",
    "        print(\"No valid producer data found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
